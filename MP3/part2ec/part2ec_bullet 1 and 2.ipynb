{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\123\\Anaconda2\\lib\\site-packages\\sklearn\\lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as dist\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import math\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.lda import LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================\n",
    "bullet one starts from here\n",
    "================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combination of 8 y/n\n",
    "# sequence = label\n",
    "# 1 = yes, 0 = no\n",
    "\n",
    "# each dataset has shape 25 x 150\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. divide the training data into individual words\n",
    "\n",
    "method: hamming window\n",
    "\n",
    "total length = 150 \n",
    "\n",
    "by overservation, split into 10 frames: 8 words and start, end (2) \n",
    "\n",
    "len = 15, M is the overlap. \n",
    "\n",
    "1. try M = 2 (head and tail) and ignore start and end frame\n",
    "\n",
    "2. try M = 1 for tail and ignore start and end frame\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFiles():\n",
    "    files = glob.glob(\"training/*.txt\")\n",
    "\n",
    "    \n",
    "    #threshold is the start of the slicing\n",
    "    #set threshold to converge the best solution\n",
    "    \n",
    "    # 1 = yes, 0 = no\n",
    "    \n",
    "    training0 = []    # 25 * 10 for each sample and space 3 lines\n",
    "    training1 = []  \n",
    "    \n",
    "    for fileName in files:\n",
    "        with open(fileName) as file_:\n",
    "            # fileName get label \n",
    "            labels = fileName[9:-4].split(\"_\")\n",
    "            # zero padding = [3, 10]\n",
    "            \n",
    "            padding = np.zeros(shape = (3, 10))\n",
    "            \n",
    "#             print len(labels)\n",
    "            threshold = 1\n",
    "            \n",
    "\n",
    "            \n",
    "            # slicing it and seperate into yes_train and no_train\n",
    "            # \" \" = high   =  1\n",
    "            # \"%\" = low    =  0\n",
    "            rawdata = np.zeros(shape = (25,150))\n",
    "            counter = 0 # count num of lines\n",
    "            for line in file_:\n",
    "                for i in range(len(line)-1):\n",
    "                    if line[i] == \" \":\n",
    "                        rawdata[counter][i] = 1\n",
    "                counter += 1\n",
    "            \n",
    "            \n",
    "            newstart = 0\n",
    "            num_slicing = 0\n",
    "            \n",
    "            for cow in range(len(line)-1):\n",
    "                if num_slicing >= 8:\n",
    "                    break\n",
    "                if cow < newstart:\n",
    "                    continue\n",
    "                if np.sum(rawdata[:,cow]) > threshold:\n",
    "                    #start slicing\n",
    "#                     print num_slicing\n",
    "                    if labels[num_slicing] == \"0\":   #no                        \n",
    "                        if len(training0) == 0:\n",
    "                            training0 = rawdata[:,cow:cow+10]\n",
    "                        else:\n",
    "                            training0 = np.concatenate( (training0,rawdata[:,cow:cow+10]),  axis = 0)\n",
    "                        \n",
    "                        training0 = np.concatenate( (training0,padding),  axis = 0)\n",
    "                    else:\n",
    "                        if len(training1) == 0:\n",
    "                            training1 = rawdata[:,cow:cow+10]\n",
    "                        else:\n",
    "                            training1 = np.concatenate( (training1,rawdata[:,cow:cow+10]),  axis = 0)                              \n",
    "                        training1 = np.concatenate( (training1,padding),  axis = 0)\n",
    "                    \n",
    "                    newstart = cow + 10\n",
    "                    \n",
    "                    #after slicing\n",
    "                    num_slicing += 1\n",
    "#     print len(training0)/28, len(training1)/28\n",
    "    return (training1,training0)   # (yes,no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251 229\n"
     ]
    }
   ],
   "source": [
    "trainingdata = readFiles()\n",
    "\n",
    "yes_num = len(trainingdata[0])/28\n",
    "no_num = len(trainingdata[1])/28\n",
    "\n",
    "print yes_num, no_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   yes is class 0\n",
    "#   no is class 1\n",
    "k = 0.35\n",
    "    \n",
    "def training(yes_train, no_train, yes_num, no_num):\n",
    "    # \" \" = high   =  1\n",
    "    # \"%\" = low    =  0\n",
    "    \n",
    "    class_total = [yes_num, no_num]\n",
    "\n",
    "    training0 = np.zeros(shape=(2, 25, 10))   #low\n",
    "    training1 = np.zeros(shape=(2, 25, 10))   #high\n",
    "\n",
    "    count = 0\n",
    "    for i in range(int(yes_num)):\n",
    "        for row in range(25):\n",
    "            for col in range(10):\n",
    "                if yes_train[i*28 + row][col] == 1:   #high\n",
    "                    training1[0][row][col] += 1\n",
    "                    training0[0][row][col] += 0\n",
    "                else:\n",
    "                    training1[0][row][col] += 0\n",
    "                    training0[0][row][col] += 1\n",
    "                    \n",
    "    for i in range(int(no_num)):\n",
    "        for row in range(25):\n",
    "            for col in range(10):\n",
    "                if no_train[i*28 + row][col] == 1:   #high\n",
    "                    training1[1][row][col] += 1\n",
    "                    training0[1][row][col] += 0\n",
    "                else:\n",
    "                    training1[1][row][col] += 0\n",
    "                    training0[1][row][col] += 1\n",
    "\n",
    "    for i in range(2):\n",
    "        training1[i] = (training1[i] + k) / (class_total[i] + k * 2)\n",
    "        training0[i] = (training0[i] + k) / (class_total[i] + k * 2)\n",
    "#     print(training0[1][0])\n",
    "#     print(training1[1][0])\n",
    "    \n",
    "    return training0, training1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training0, training1 = training(trainingdata[0],trainingdata[1],yes_num,no_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print trainingYes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readTestFiles(directory):\n",
    "    padding = np.zeros(shape = (3, 10))    \n",
    "    files = glob.glob(directory)\n",
    "    \n",
    "    testingdata = []\n",
    "    \n",
    "    for fileName in files:\n",
    "        with open(fileName) as file_:\n",
    "            sample = [list(line)[0:10] for line in file_]\n",
    "        if len(testingdata) == 0:\n",
    "            testingdata = sample\n",
    "        else:\n",
    "            testingdata = np.concatenate((testingdata,sample), axis = 0)\n",
    "        testingdata = np.concatenate((testingdata,padding), axis = 0)\n",
    "\n",
    "    return testingdata\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_no = readTestFiles(\"no_test/*.txt\")\n",
    "test_yes = readTestFiles(\"yes_test/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "Num_test_no = len(test_no) / 28\n",
    "Num_test_yes = len(test_yes) / 28\n",
    "print Num_test_no\n",
    "print Num_test_yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# log P(class) + log P(f1,1 | class) + log P(f1,2 | class) + ... + log P(f28,28 | class)\n",
    "\n",
    "# test_rough = inputDigit(name = \"digitdata/testimages\")\n",
    "def testing(yes_test, no_test, Num_test_yes, Num_test_no):\n",
    "\n",
    "    data_test = np.concatenate( (yes_test, no_test) , axis = 0 )\n",
    "# #     print len(data_test) / 28\n",
    "#     return \n",
    "\n",
    "    total = Num_test_yes + Num_test_no\n",
    "    answer = np.zeros(int(total))\n",
    "    \n",
    "    class_total = [Num_test_yes, Num_test_no]\n",
    "    \n",
    "    for i in range(int(total)):\n",
    "        test_image = np.zeros(shape=(25,10))\n",
    "        for row in range(25):\n",
    "            for col in range(10):\n",
    "                if data_test[i*28+row][col] == ' ':\n",
    "                    test_image[row][col] = 1\n",
    "                else:\n",
    "                    test_image[row][col] = 0\n",
    "                    \n",
    "\n",
    "        posteriori = np.zeros(2)\n",
    "        for class_num in range(2):\n",
    "            posteriori[class_num] = math.log(class_total[class_num])\n",
    "            for row in range(25):\n",
    "                for col in range(10):\n",
    "                    if test_image[row][col] == 0:\n",
    "                        posteriori[class_num] += math.log(training0[class_num][row][col])\n",
    "                    else:\n",
    "                        posteriori[class_num] += math.log(training1[class_num][row][col] )   \n",
    "        answer[i] = np.argmax(posteriori)\n",
    "#     print answer\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(pred):\n",
    "    conf_matrix = np.zeros(shape=(2,2))\n",
    "    #print(conf_matrix[0][0])\n",
    "    #print(int(answer[0]))\n",
    "    for i in range(100):\n",
    "        if i < 50:\n",
    "            conf_matrix[0][int(pred[i])] += 1\n",
    "        else:\n",
    "            conf_matrix[1][int(pred[i])] += 1\n",
    "            \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            conf_matrix[i][j] /= 50.0\n",
    "    \n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98  0.02]\n",
      "[ 0.06  0.94]\n",
      "overall_accuracy = 0.96\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix\n",
    "answer = testing(test_yes, test_no, Num_test_yes, Num_test_no)\n",
    "conf_matrix = confusion_matrix(answer)\n",
    "conf_matrix = np.around(conf_matrix, 2)\n",
    "for row in conf_matrix:\n",
    "    print(row)\n",
    "overall_accuracy = 0\n",
    "for i in range(2):\n",
    "    overall_accuracy += conf_matrix[i][i] * 50.0\n",
    "print(\"overall_accuracy = \" + str(overall_accuracy/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy =', 0.94999999999999996, 'when k is ', 9.9999999999999995e-07)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 1.0000000000000001e-05)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 0.0001)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 0.001)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 0.002)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.0050000000000000001)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.01)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.02)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.050000000000000003)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.10000000000000001)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.20000000000000001)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.30000000000000004)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.40000000000000002)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.5)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.59999999999999998)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.70000000000000007)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 0.80000000000000004)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.90000000000000002)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 1.0)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 1.1000000000000001)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 1.2000000000000002)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 1.3000000000000003)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 1.4000000000000001)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 1.5000000000000002)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 1.6000000000000001)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 1.7000000000000002)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 1.8000000000000003)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 1.9000000000000001)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 2.0)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 2.1000000000000001)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 2.2000000000000002)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 2.3000000000000003)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 2.4000000000000004)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 2.5000000000000004)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 2.6000000000000001)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 2.7000000000000002)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 2.8000000000000003)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 2.9000000000000004)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 3.0000000000000004)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 3.1000000000000001)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 3.2000000000000002)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 3.3000000000000003)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 3.4000000000000004)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 3.5000000000000004)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 3.6000000000000001)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 3.7000000000000002)\n",
      "('accuracy =', 0.94999999999999996, 'when k is ', 3.8000000000000003)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 3.9000000000000004)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 4.0)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 4.0999999999999996)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 4.2000000000000002)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 4.2999999999999998)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 4.3999999999999995)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 4.5)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 4.5999999999999996)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 4.7000000000000002)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 4.7999999999999998)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 4.9000000000000004)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 5.0)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 5.0999999999999996)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 5.2000000000000002)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 5.2999999999999998)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 5.4000000000000004)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 5.5)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 5.5999999999999996)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 5.7000000000000002)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 5.7999999999999998)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 5.9000000000000004)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 6.0)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 6.0999999999999996)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 6.2000000000000002)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 6.2999999999999998)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 6.4000000000000004)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 6.5)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 6.5999999999999996)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 6.7000000000000002)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 6.7999999999999998)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 6.9000000000000004)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 7.0)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 7.0999999999999996)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 7.2000000000000002)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 7.2999999999999998)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 7.4000000000000004)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 7.5)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 7.5999999999999996)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 7.7000000000000002)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 7.7999999999999998)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 7.9000000000000004)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 8.0)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 8.0999999999999996)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 8.1999999999999993)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 8.3000000000000007)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 8.4000000000000004)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 8.5)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 8.5999999999999996)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 8.6999999999999993)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 8.8000000000000007)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 8.9000000000000004)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 9.0)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 9.0999999999999996)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 9.1999999999999993)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 9.3000000000000007)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 9.4000000000000004)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 9.5)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 9.5999999999999996)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 9.7000000000000011)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 9.8000000000000007)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 9.9000000000000004)\n",
      "('accuracy =', 0.93999999999999995, 'when k is ', 10.0)\n"
     ]
    }
   ],
   "source": [
    "# Laplace smoothing constant\n",
    "k1 = np.array([10**(-6), 10**(-5), 10**(-4), 0.001, 0.002, 0.005, 0.01, 0.02, 0.05])\n",
    "k2 = np.linspace(0.1, 10, 100)\n",
    "k_grid = np.append(k1, k2)\n",
    "\n",
    "accuracy = np.zeros(109)\n",
    "\n",
    "for k_index in range(109):\n",
    "    k = k_grid[k_index]\n",
    "    #print(k)\n",
    "    training0, training1 = training(trainingdata[0],trainingdata[1],yes_num,no_num)\n",
    "    answer = testing(test_yes, test_no, Num_test_yes, Num_test_no)\n",
    "    conf_matrix = confusion_matrix(answer)\n",
    "    overall_accuracy = 0\n",
    "    for i in range(2):\n",
    "        overall_accuracy += conf_matrix[i][i] * 50.0\n",
    "        accuracy[k_index] = overall_accuracy\n",
    "    print(\"accuracy =\", overall_accuracy/100.0, \"when k is \", k_grid[k_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x9e87710>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9e0a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "#ax.set_xscale('log')\n",
    "plt.scatter(k_grid[5:], accuracy[5:], label = 'f(x)')\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy (percent)\")\n",
    "plt.title(\"Accuracy vs smoothing constant k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy =', 0.94999999999999996, 'when k is ', 0.0001)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.011962711864406778)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.023825423728813556)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.035688135593220337)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.047550847457627117)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.059413559322033897)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.071276271186440671)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.083138983050847451)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.095001694915254231)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.10686440677966101)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.11872711864406779)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.13058983050847456)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.14245254237288132)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.15431525423728812)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.16617796610169489)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.17804067796610168)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.18990338983050845)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.20176610169491521)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.21362881355932201)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.22549152542372877)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.23735423728813557)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.24921694915254233)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.26107966101694913)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.27294237288135592)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.28480508474576266)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.29666779661016945)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.30853050847457625)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.32039322033898299)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.33225593220338978)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.34411864406779658)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.35598135593220337)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.36784406779661011)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.3797067796610169)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.3915694915254237)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.40343220338983043)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.41529491525423723)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.42715762711864402)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.43902033898305082)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.45088305084745756)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.46274576271186435)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.47460847457627114)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.48647118644067788)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.49833389830508468)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.51019661016949147)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.52205932203389827)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.53392203389830506)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.54578474576271185)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.55764745762711854)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.56951016949152533)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.58137288135593213)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.59323559322033892)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.60509830508474571)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.61696101694915251)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.6288237288135593)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.64068644067796598)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.65254915254237278)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.66441186440677957)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.67627457627118637)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.68813728813559316)\n",
      "('accuracy =', 0.95999999999999996, 'when k is ', 0.69999999999999996)\n"
     ]
    }
   ],
   "source": [
    "# Laplace smoothing constant\n",
    "k_grid = np.linspace(0.0001, 0.7, 60)\n",
    "\n",
    "accuracy = np.zeros(60)\n",
    "\n",
    "for k_index in range(60):\n",
    "    k = k_grid[k_index]\n",
    "    #print(k)\n",
    "    training0, training1 = training(trainingdata[0],trainingdata[1],yes_num,no_num)\n",
    "    answer = testing(test_yes, test_no, Num_test_yes, Num_test_no)\n",
    "    conf_matrix = confusion_matrix(answer)\n",
    "    overall_accuracy = 0\n",
    "    for i in range(2):\n",
    "        overall_accuracy += conf_matrix[i][i] * 50\n",
    "        accuracy[k_index] = overall_accuracy\n",
    "    print(\"accuracy =\", overall_accuracy/100, \"when k is \", k_grid[k_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA\n",
    "==============\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\123\\Anaconda2\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:161: UserWarning: pylab import has clobbered these variables: ['dist']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as dist\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFiles():\n",
    "    files = glob.glob(\"training/*.txt\")\n",
    "\n",
    "    \n",
    "    #threshold is the start of the slicing\n",
    "    #set threshold to converge the best solution\n",
    "    \n",
    "    # 1 = yes, 0 = no\n",
    "    \n",
    "    training0 = []    # 25 * 10 for each sample and space 3 lines\n",
    "    training1 = []  \n",
    "    \n",
    "    for fileName in files:\n",
    "        with open(fileName) as file_:\n",
    "            # fileName get label \n",
    "            labels = fileName[9:-4].split(\"_\")\n",
    "            # zero padding = [3, 10]\n",
    "            \n",
    "            #padding = np.zeros(shape = (3, 10))\n",
    "            \n",
    "#             print len(labels)\n",
    "            threshold = 1\n",
    "            \n",
    "\n",
    "            \n",
    "            # slicing it and seperate into yes_train and no_train\n",
    "            # \" \" = high   =  1\n",
    "            # \"%\" = low    =  0\n",
    "            rawdata = np.zeros(shape = (25,150))\n",
    "            counter = 0 # count num of lines\n",
    "            for line in file_:\n",
    "                for i in range(len(line)-1):\n",
    "                    if line[i] == \" \":\n",
    "                        rawdata[counter][i] = 1\n",
    "                counter += 1\n",
    "            \n",
    "            \n",
    "            newstart = 0\n",
    "            num_slicing = 0\n",
    "            \n",
    "            for cow in range(len(line)-1):\n",
    "                if num_slicing >= 8:\n",
    "                    break\n",
    "                if cow < newstart:\n",
    "                    continue\n",
    "                if np.sum(rawdata[:,cow]) > threshold:\n",
    "                    #start slicing\n",
    "#                     print num_slicing\n",
    "#                     print rawdata[:,cow:cow+10].shape\n",
    "                    if labels[num_slicing] == \"0\":   #no\n",
    "                        temp_training0 = np.reshape(rawdata[:,cow:cow+10],(1,250))\n",
    "                        if len(training0) == 0:\n",
    "                            training0 = temp_training0\n",
    "                        else:\n",
    "                            training0 = np.concatenate( (training0,temp_training0),  axis = 0)\n",
    "                        \n",
    "#                         training0 = np.concatenate( (training0,padding),  axis = 0)\n",
    "                    else:\n",
    "                        temp_training1 = np.reshape(rawdata[:,cow:cow+10],(1,250))\n",
    "                        if len(training1) == 0:\n",
    "                            training1 = temp_training1\n",
    "                        else:\n",
    "                            training1 = np.concatenate( (training1,temp_training1),  axis = 0)                              \n",
    "#                         training1 = np.concatenate( (training1,padding),  axis = 0)\n",
    "                    \n",
    "                    newstart = cow + 10\n",
    "                    \n",
    "                    #after slicing\n",
    "                    num_slicing += 1\n",
    "#     print len(training0)/28, len(training1)/28\n",
    "    print training1.shape, training0.shape\n",
    "    return (training1,training0)   # (yes,no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251L, 250L) (229L, 250L)\n"
     ]
    }
   ],
   "source": [
    "trainingdata = readFiles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainLDA(trainfeat,trainlabel):\n",
    "    nlabels=int(trainlabel.max())+1 #Assuming all labels up to nlabels exist.\n",
    "    pi=np.zeros(nlabels) # store your prior in here\n",
    "    means=np.zeros((nlabels,trainfeat.shape[1])) # store the class means in here\n",
    "    cov=np.zeros((trainfeat.shape[1],trainfeat.shape[1])) # store the covariance matrix in here\n",
    "    # Put your code here\n",
    "    #print (pi.shape, means.shape, cov.shape)\n",
    "    #nlabels = M\n",
    "    for i in range(0, nlabels):\n",
    "        pi[i] = float(np.sum(trainlabel==i)) / trainlabel.size\n",
    "        \n",
    "        for j in range(0, trainfeat.shape[0]):\n",
    "            if int(trainlabel[j]) == i:\n",
    "                means[i] += trainfeat[j] / float(np.sum(trainlabel==i))\n",
    "            # means[i] = float(np.sum(trainfeat[trainlabel==i])) / np.sum(trainlabel==i) \n",
    "    \n",
    "         \n",
    "    \n",
    "    for i in range(0, nlabels):\n",
    "        for j in range(0,trainlabel.size):\n",
    "            #cov += np.outer(trainfeat[trainlabel[j]==i] -  means[i], trainfeat[trainlabel[j]==i] -  means[i]) \n",
    "            if(trainlabel[j] == i):\n",
    "                cov += np.outer(trainfeat[j] -  means[i], trainfeat[j] -  means[i]) \n",
    "    \n",
    "    cov = cov /(trainlabel.size - nlabels )\n",
    "    \n",
    "    return (pi,means,cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "trainfeat = np.concatenate((trainingdata[0],trainingdata[1]) , axis = 0 )\n",
    "yes_label = np.zeros(yes_num)\n",
    "no_label = np.ones(no_num)\n",
    "\n",
    "trainlabel = np.concatenate((yes_label,no_label) , axis = 0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi : \n",
      "(2L,)\n",
      "Means : \n",
      "(2L, 250L)\n",
      "Cov : \n",
      "(250L, 250L)\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "LDAAttributes = trainLDA(trainfeat, trainlabel)\n",
    "\n",
    "print(\"Pi : \")\n",
    "print LDAAttributes[0].shape\n",
    "print(\"Means : \")\n",
    "print LDAAttributes[1].shape\n",
    "print(\"Cov : \")\n",
    "print LDAAttributes[2].shape\n",
    "#print(\"Training error : \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\123\\Anaconda2\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LDA(n_components=None, priors=None, shrinkage=None, solver='svd',\n",
       "  store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.lda import LDA\n",
    "# Put your code here\n",
    "LDA = LDA()\n",
    "LDA.fit(trainfeat, trainlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readTestFiles(directory):\n",
    "#     padding = np.zeros(shape = (3, 10))    \n",
    "    files = glob.glob(directory)\n",
    "    \n",
    "    testingdata = []\n",
    "    \n",
    "    for fileName in files:\n",
    "        with open(fileName) as file_:\n",
    "            sample = np.reshape([list(line)[0:10] for line in file_],(1,250))\n",
    "        if len(testingdata) == 0:\n",
    "            testingdata = sample\n",
    "        else:\n",
    "            testingdata = np.concatenate((testingdata,sample), axis = 0)\n",
    "#         testingdata = np.concatenate((testingdata,padding), axis = 0)\n",
    "\n",
    "    return testingdata\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n"
     ]
    }
   ],
   "source": [
    "test_no = readTestFiles(\"no_test/*.txt\")\n",
    "test_yes = readTestFiles(\"yes_test/*.txt\")\n",
    "\n",
    " \n",
    "\n",
    "yes_label = np.zeros(50)\n",
    "no_label = np.ones(50)\n",
    "\n",
    "testlabel = np.concatenate((yes_label,no_label) , axis = 0 )\n",
    "\n",
    "data_test = np.concatenate( (test_yes, test_no) , axis = 0 )\n",
    "# print data_test.shape[0]\n",
    "\n",
    "test_data = np.zeros(data_test.shape)\n",
    "\n",
    "for i in range(data_test.shape[0]):\n",
    "    for j in  range(data_test.shape[1]):        \n",
    "        if data_test[i,j] == ' ':\n",
    "            test_data[i,j] = 1\n",
    "    \n",
    "\n",
    "classification = LDA.predict(test_data)\n",
    "error = classifierError(testlabel,classification)\n",
    "\n",
    "print 1-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifierError(truelabels,estimatedlabels):\n",
    "    # Put your code here\n",
    "    loss = 0\n",
    "    for i in range(0,truelabels.size):\n",
    "        if(truelabels[i] != estimatedlabels[i] ):\n",
    "            loss = loss + 1\n",
    "    \n",
    "    return float (loss) / truelabels.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
