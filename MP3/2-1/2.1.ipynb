{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as dist\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import math\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \" \" = high   =  1\n",
    "# \"%\" = low    =  0\n",
    "# len(row) = 10\n",
    "def countNum(name = \"yes_train.txt\"):\n",
    "    with open(name) as dataset:\n",
    "        num_lines = sum(1 for line in dataset)\n",
    "        return num_lines / 28\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.0 131.0\n"
     ]
    }
   ],
   "source": [
    "# label yes = 1\n",
    "# label no = 0\n",
    "Num_sample_yes =  countNum()\n",
    "Num_sample_no =  countNum(\"no_train.txt\")\n",
    "print(Num_sample_yes,Num_sample_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0 50.0\n"
     ]
    }
   ],
   "source": [
    "Num_test_yes =  countNum(\"yes_test.txt\")\n",
    "Num_test_no =  countNum(\"no_test.txt\")\n",
    "print(Num_test_yes,Num_test_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputDigit(name=\"yes_train.txt\"):\n",
    "    with open(name) as digitTxt:\n",
    "        image = [list(line)[0:10] for line in digitTxt]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yes = inputDigit()\n",
    "data_no = inputDigit(\"no_train.txt\")\n",
    "test_yes = inputDigit(\"yes_test.txt\")\n",
    "test_no = inputDigit(\"no_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   yes is class 0\n",
    "#   no is class 1\n",
    "k = 3.3\n",
    "    \n",
    "def training(yes_train, no_train, yes_num, no_num):\n",
    "    # \" \" = high   =  1\n",
    "    # \"%\" = low    =  0\n",
    "    \n",
    "    class_total = [yes_num, no_num]\n",
    "\n",
    "    training0 = np.zeros(shape=(2, 25, 10))   #high\n",
    "    training1 = np.zeros(shape=(2, 25, 10))   #low\n",
    "\n",
    "    count = 0\n",
    "    for i in range(int(yes_num)):\n",
    "        for row in range(25):\n",
    "            for col in range(10):\n",
    "                if yes_train[i*28 + row][col] == ' ':      # offset = i*28, since 25 + 3(blank rows)\n",
    "                    training1[0][row][col] += 1\n",
    "                else:\n",
    "                    training0[0][row][col] += 1\n",
    "                    \n",
    "    for i in range(int(no_num)):\n",
    "        for row in range(25):\n",
    "            for col in range(10):\n",
    "                if no_train[i*28 + row][col] == ' ':\n",
    "                    training1[1][row][col] += 1\n",
    "                else:\n",
    "                    training0[1][row][col] += 1\n",
    "\n",
    "    # laplace smooth\n",
    "    for i in range(2):\n",
    "        training1[i] = (training1[i] + k) / (class_total[i] + k * 2)\n",
    "        \n",
    "        training0[i] = (training0[i] + k) / (class_total[i] + k * 2)\n",
    "#     print(training0[1][0])\n",
    "#     print(training1[1][0])\n",
    "    return training0, training1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "training0, training1 = training(data_yes, data_no, Num_sample_yes, Num_sample_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log P(class) + log P(f1,1 | class) + log P(f1,2 | class) + ... + log P(f28,28 | class)\n",
    "\n",
    "# test_rough = inputDigit(name = \"digitdata/testimages\")\n",
    "def testing(yes_test, no_test, Num_test_yes, Num_test_no):\n",
    "\n",
    "    data_test = np.concatenate( (yes_test, no_test) , axis = 0 )\n",
    "# #     print len(data_test) / 28\n",
    "#     return \n",
    "\n",
    "    total = Num_test_yes + Num_test_no\n",
    "    answer = np.zeros(int(total))\n",
    "    \n",
    "    class_total = [Num_test_yes, Num_test_no]\n",
    "    \n",
    "    for i in range(int(total)):\n",
    "        test_image = np.zeros(shape=(25,10))\n",
    "        for row in range(25):\n",
    "            for col in range(10):\n",
    "                if data_test[i*28+row][col] == ' ':\n",
    "                    test_image[row][col] = 1\n",
    "                else:\n",
    "                    test_image[row][col] = 0\n",
    "                    \n",
    "\n",
    "        posteriori = np.zeros(2)\n",
    "        for class_num in range(2):\n",
    "            posteriori[class_num] = math.log(class_total[class_num])\n",
    "            for row in range(25):\n",
    "                for col in range(10):\n",
    "                    if test_image[row][col] == 0:\n",
    "                        posteriori[class_num] += math.log(training0[class_num][row][col])\n",
    "                    else:\n",
    "                        posteriori[class_num] += math.log(training1[class_num][row][col] )   \n",
    "        answer[i] = np.argmax(posteriori)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = testing(test_yes, test_no, Num_test_yes, Num_test_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(pred):\n",
    "    conf_matrix = np.zeros(shape=(2,2))\n",
    "    #print(conf_matrix[0][0])\n",
    "    #print(int(answer[0]))\n",
    "    for i in range(100):\n",
    "        if i < 50:\n",
    "            conf_matrix[0][int(pred[i])] += 1\n",
    "        else:\n",
    "            conf_matrix[1][int(pred[i])] += 1\n",
    "            \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            conf_matrix[i][j] /= 50.0\n",
    "    \n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98  0.02]\n",
      "[ 0.04  0.96]\n",
      "overall_accuracy = 0.97\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix\n",
    "conf_matrix = confusion_matrix(answer)\n",
    "conf_matrix = np.around(conf_matrix, 2)\n",
    "for row in conf_matrix:\n",
    "    print(row)\n",
    "overall_accuracy = 0\n",
    "for i in range(2):\n",
    "    overall_accuracy += conf_matrix[i][i] * 50.0\n",
    "print(\"overall_accuracy = \" + str(overall_accuracy/100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's find the best k##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.95 when k is  1e-06\n",
      "accuracy = 0.95 when k is  1e-05\n",
      "accuracy = 0.95 when k is  0.0001\n",
      "accuracy = 0.96 when k is  0.001\n",
      "accuracy = 0.96 when k is  0.002\n",
      "accuracy = 0.96 when k is  0.005\n",
      "accuracy = 0.96 when k is  0.01\n",
      "accuracy = 0.96 when k is  0.02\n",
      "accuracy = 0.96 when k is  0.05\n",
      "accuracy = 0.96 when k is  0.1\n",
      "accuracy = 0.96 when k is  0.2\n",
      "accuracy = 0.96 when k is  0.3\n",
      "accuracy = 0.96 when k is  0.4\n",
      "accuracy = 0.96 when k is  0.5\n",
      "accuracy = 0.96 when k is  0.6\n",
      "accuracy = 0.96 when k is  0.7\n",
      "accuracy = 0.96 when k is  0.8\n",
      "accuracy = 0.96 when k is  0.9\n",
      "accuracy = 0.96 when k is  1.0\n",
      "accuracy = 0.96 when k is  1.1\n",
      "accuracy = 0.96 when k is  1.2\n",
      "accuracy = 0.96 when k is  1.3\n",
      "accuracy = 0.96 when k is  1.4\n",
      "accuracy = 0.96 when k is  1.5\n",
      "accuracy = 0.96 when k is  1.6\n",
      "accuracy = 0.96 when k is  1.7\n",
      "accuracy = 0.96 when k is  1.8\n",
      "accuracy = 0.96 when k is  1.9\n",
      "accuracy = 0.96 when k is  2.0\n",
      "accuracy = 0.96 when k is  2.1\n",
      "accuracy = 0.96 when k is  2.2\n",
      "accuracy = 0.96 when k is  2.3\n",
      "accuracy = 0.96 when k is  2.4\n",
      "accuracy = 0.96 when k is  2.5\n",
      "accuracy = 0.96 when k is  2.6\n",
      "accuracy = 0.96 when k is  2.7\n",
      "accuracy = 0.96 when k is  2.8\n",
      "accuracy = 0.96 when k is  2.9\n",
      "accuracy = 0.97 when k is  3.0\n",
      "accuracy = 0.97 when k is  3.1\n",
      "accuracy = 0.97 when k is  3.2\n",
      "accuracy = 0.97 when k is  3.3\n",
      "accuracy = 0.97 when k is  3.4\n",
      "accuracy = 0.97 when k is  3.5\n",
      "accuracy = 0.97 when k is  3.6\n",
      "accuracy = 0.96 when k is  3.7\n",
      "accuracy = 0.96 when k is  3.8\n",
      "accuracy = 0.96 when k is  3.9\n",
      "accuracy = 0.96 when k is  4.0\n",
      "accuracy = 0.96 when k is  4.1\n",
      "accuracy = 0.96 when k is  4.2\n",
      "accuracy = 0.96 when k is  4.3\n",
      "accuracy = 0.96 when k is  4.4\n",
      "accuracy = 0.96 when k is  4.5\n",
      "accuracy = 0.96 when k is  4.6\n",
      "accuracy = 0.96 when k is  4.7\n",
      "accuracy = 0.96 when k is  4.8\n",
      "accuracy = 0.96 when k is  4.9\n",
      "accuracy = 0.96 when k is  5.0\n",
      "accuracy = 0.96 when k is  5.1\n",
      "accuracy = 0.96 when k is  5.2\n",
      "accuracy = 0.96 when k is  5.3\n",
      "accuracy = 0.96 when k is  5.4\n",
      "accuracy = 0.96 when k is  5.5\n",
      "accuracy = 0.96 when k is  5.6\n",
      "accuracy = 0.96 when k is  5.7\n",
      "accuracy = 0.96 when k is  5.8\n",
      "accuracy = 0.96 when k is  5.9\n",
      "accuracy = 0.96 when k is  6.0\n",
      "accuracy = 0.96 when k is  6.1\n",
      "accuracy = 0.96 when k is  6.2\n",
      "accuracy = 0.96 when k is  6.3\n",
      "accuracy = 0.96 when k is  6.4\n",
      "accuracy = 0.96 when k is  6.5\n",
      "accuracy = 0.96 when k is  6.6\n",
      "accuracy = 0.96 when k is  6.7\n",
      "accuracy = 0.96 when k is  6.8\n",
      "accuracy = 0.96 when k is  6.9\n",
      "accuracy = 0.96 when k is  7.0\n",
      "accuracy = 0.96 when k is  7.1\n",
      "accuracy = 0.96 when k is  7.2\n",
      "accuracy = 0.96 when k is  7.3\n",
      "accuracy = 0.96 when k is  7.4\n",
      "accuracy = 0.96 when k is  7.5\n",
      "accuracy = 0.96 when k is  7.6\n",
      "accuracy = 0.96 when k is  7.7\n",
      "accuracy = 0.96 when k is  7.8\n",
      "accuracy = 0.95 when k is  7.9\n",
      "accuracy = 0.95 when k is  8.0\n",
      "accuracy = 0.95 when k is  8.1\n",
      "accuracy = 0.95 when k is  8.2\n",
      "accuracy = 0.95 when k is  8.3\n",
      "accuracy = 0.95 when k is  8.4\n",
      "accuracy = 0.95 when k is  8.5\n",
      "accuracy = 0.94 when k is  8.6\n",
      "accuracy = 0.94 when k is  8.7\n",
      "accuracy = 0.94 when k is  8.8\n",
      "accuracy = 0.94 when k is  8.9\n",
      "accuracy = 0.94 when k is  9.0\n",
      "accuracy = 0.94 when k is  9.1\n",
      "accuracy = 0.94 when k is  9.2\n",
      "accuracy = 0.94 when k is  9.3\n",
      "accuracy = 0.94 when k is  9.4\n",
      "accuracy = 0.94 when k is  9.5\n",
      "accuracy = 0.94 when k is  9.6\n",
      "accuracy = 0.94 when k is  9.7\n",
      "accuracy = 0.94 when k is  9.8\n",
      "accuracy = 0.94 when k is  9.9\n",
      "accuracy = 0.94 when k is  10.0\n"
     ]
    }
   ],
   "source": [
    "# Laplace smoothing constant\n",
    "k1 = np.array([10**(-6), 10**(-5), 10**(-4), 0.001, 0.002, 0.005, 0.01, 0.02, 0.05])\n",
    "k2 = np.linspace(0.1, 10, 100)\n",
    "k_grid = np.append(k1, k2)\n",
    "\n",
    "accuracy = np.zeros(109)\n",
    "\n",
    "for k_index in range(109):\n",
    "    k = k_grid[k_index]\n",
    "    #print(k)\n",
    "    training0, training1 = training(data_yes, data_no, Num_sample_yes, Num_sample_no)\n",
    "    answer = testing(test_yes, test_no, Num_test_yes, Num_test_no)\n",
    "    conf_matrix = confusion_matrix(answer)\n",
    "    overall_accuracy = 0\n",
    "    for i in range(2):\n",
    "        overall_accuracy += conf_matrix[i][i] * 50.0\n",
    "        accuracy[k_index] = overall_accuracy\n",
    "    print(\"accuracy =\", overall_accuracy/100.0, \"when k is \", k_grid[k_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7ff803438668>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff80597a908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "#ax.set_xscale('log')\n",
    "plt.scatter(k_grid[5:], accuracy[5:], label = 'f(x)')\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy (percent)\")\n",
    "plt.title(\"Accuracy vs smoothing constant k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.97 when k is  3.0\n",
      "accuracy = 0.97 when k is  3.01016949153\n",
      "accuracy = 0.97 when k is  3.02033898305\n",
      "accuracy = 0.97 when k is  3.03050847458\n",
      "accuracy = 0.97 when k is  3.0406779661\n",
      "accuracy = 0.97 when k is  3.05084745763\n",
      "accuracy = 0.97 when k is  3.06101694915\n",
      "accuracy = 0.97 when k is  3.07118644068\n",
      "accuracy = 0.97 when k is  3.0813559322\n",
      "accuracy = 0.97 when k is  3.09152542373\n",
      "accuracy = 0.97 when k is  3.10169491525\n",
      "accuracy = 0.97 when k is  3.11186440678\n",
      "accuracy = 0.97 when k is  3.12203389831\n",
      "accuracy = 0.97 when k is  3.13220338983\n",
      "accuracy = 0.97 when k is  3.14237288136\n",
      "accuracy = 0.97 when k is  3.15254237288\n",
      "accuracy = 0.97 when k is  3.16271186441\n",
      "accuracy = 0.97 when k is  3.17288135593\n",
      "accuracy = 0.97 when k is  3.18305084746\n",
      "accuracy = 0.97 when k is  3.19322033898\n",
      "accuracy = 0.97 when k is  3.20338983051\n",
      "accuracy = 0.97 when k is  3.21355932203\n",
      "accuracy = 0.97 when k is  3.22372881356\n",
      "accuracy = 0.97 when k is  3.23389830508\n",
      "accuracy = 0.97 when k is  3.24406779661\n",
      "accuracy = 0.97 when k is  3.25423728814\n",
      "accuracy = 0.97 when k is  3.26440677966\n",
      "accuracy = 0.97 when k is  3.27457627119\n",
      "accuracy = 0.97 when k is  3.28474576271\n",
      "accuracy = 0.97 when k is  3.29491525424\n",
      "accuracy = 0.97 when k is  3.30508474576\n",
      "accuracy = 0.97 when k is  3.31525423729\n",
      "accuracy = 0.97 when k is  3.32542372881\n",
      "accuracy = 0.97 when k is  3.33559322034\n",
      "accuracy = 0.97 when k is  3.34576271186\n",
      "accuracy = 0.97 when k is  3.35593220339\n",
      "accuracy = 0.97 when k is  3.36610169492\n",
      "accuracy = 0.97 when k is  3.37627118644\n",
      "accuracy = 0.97 when k is  3.38644067797\n",
      "accuracy = 0.97 when k is  3.39661016949\n",
      "accuracy = 0.97 when k is  3.40677966102\n",
      "accuracy = 0.97 when k is  3.41694915254\n",
      "accuracy = 0.97 when k is  3.42711864407\n",
      "accuracy = 0.97 when k is  3.43728813559\n",
      "accuracy = 0.97 when k is  3.44745762712\n",
      "accuracy = 0.97 when k is  3.45762711864\n",
      "accuracy = 0.97 when k is  3.46779661017\n",
      "accuracy = 0.97 when k is  3.47796610169\n",
      "accuracy = 0.97 when k is  3.48813559322\n",
      "accuracy = 0.97 when k is  3.49830508475\n",
      "accuracy = 0.97 when k is  3.50847457627\n",
      "accuracy = 0.97 when k is  3.5186440678\n",
      "accuracy = 0.97 when k is  3.52881355932\n",
      "accuracy = 0.97 when k is  3.53898305085\n",
      "accuracy = 0.97 when k is  3.54915254237\n",
      "accuracy = 0.97 when k is  3.5593220339\n",
      "accuracy = 0.97 when k is  3.56949152542\n",
      "accuracy = 0.97 when k is  3.57966101695\n",
      "accuracy = 0.97 when k is  3.58983050847\n",
      "accuracy = 0.97 when k is  3.6\n"
     ]
    }
   ],
   "source": [
    "# Laplace smoothing constant\n",
    "k_grid = np.linspace(3.0, 3.6, 60)\n",
    "\n",
    "accuracy = np.zeros(60)\n",
    "\n",
    "for k_index in range(60):\n",
    "    k = k_grid[k_index]\n",
    "    #print(k)\n",
    "    training0, training1 = training(data_yes, data_no, Num_sample_yes, Num_sample_no)\n",
    "    answer = testing(test_yes, test_no, Num_test_yes, Num_test_no)\n",
    "    conf_matrix = confusion_matrix(answer)\n",
    "    overall_accuracy = 0\n",
    "    for i in range(2):\n",
    "        overall_accuracy += conf_matrix[i][i] * 50\n",
    "        accuracy[k_index] = overall_accuracy\n",
    "    print(\"accuracy =\", overall_accuracy/100, \"when k is \", k_grid[k_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
