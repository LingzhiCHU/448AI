{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "\n",
    "gamma = 0.6\n",
    "N_e = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    ball_x = 0\n",
    "    ball_y = 0\n",
    "    velocity_x = 0\n",
    "    velocity_y = 0\n",
    "    paddle_y = 0\n",
    "    terminate = False\n",
    "    \n",
    "    \n",
    "    def print_state(self):\n",
    "        print(np.around(self.ball_x, 2) , \" \" , np.around(self.ball_y, 2) , \" \" ,  \n",
    "              np.around(self.velocity_x, 2) , \" \" ,  np.around(self.velocity_y, 2) , \" \" ,  np.around(self.paddle_y, 2))\n",
    "              \n",
    " \n",
    "    def __init__(self, bx, by, vx, vy, p):\n",
    "        self.ball_x = bx\n",
    "        self.ball_y = by\n",
    "        self.velocity_x = vx\n",
    "        self.velocity_y = vy\n",
    "        self.paddle_y = p\n",
    "        \n",
    "         \n",
    "    def up(self):\n",
    "        self.paddle_y = max(self.paddle_y - 0.04, 0)\n",
    "        \n",
    "        self.update()\n",
    "        #print(\"in function up\", match(self))\n",
    "\n",
    "    def down(self):\n",
    "        self.paddle_y = min(self.paddle_y + 0.04, 0.8)\n",
    "        self.update()\n",
    "\n",
    "    def update(self):\n",
    "        global num_bounce\n",
    "#         global state_tracker\n",
    "        \n",
    "        self.ball_x += self.velocity_x\n",
    "        self.ball_y += self.velocity_y\n",
    "        \n",
    "        if self.ball_x >= 1:        # hitting right bound\n",
    "            \n",
    "            \n",
    "            if self.ball_y >= self.paddle_y and self.ball_y <= self.paddle_y + 0.2:    # hitting paddle\n",
    "                self.ball_x = 2 - self.ball_x\n",
    "                #print(\"bounce\")\n",
    "                num_bounce += 1\n",
    "#                 if curr_state not in state_tracker:\n",
    "#                     #print(curr_state)\n",
    "#                     state_tracker.append(curr_state)\n",
    "                                \n",
    "                self.velocity_x = -self.velocity_x + np.random.uniform(-0.015, 0.015)\n",
    "                if self.velocity_x < 0:\n",
    "                    self.velocity_x = min(-0.03, self.velocity_x)\n",
    "                else:\n",
    "                    self.velocity_x = max(0.03, self.velocity_x)\n",
    "                if self.velocity_x > 1:\n",
    "                    self.velocity_x = 1\n",
    "                elif self.velocity_x < -1:\n",
    "                    self.velocity_x = -1\n",
    "                \n",
    "                self.velocity_y += np.random.uniform(-0.03, 0.03)\n",
    "                if self.velocity_y > 1:\n",
    "                    self.velocity_y = 1\n",
    "                elif self.velocity_y < -1:\n",
    "                    self.velocity_y = -1\n",
    "                    \n",
    "                \n",
    "                state_tracker = []\n",
    "                \n",
    "            else:    # missing paddle\n",
    "                #print(\"terminate\")\n",
    "                self.ball_x = 2 - self.ball_x\n",
    "#                 reward(state_tracker,-1)\n",
    "#                 state_tracker = []\n",
    "                self.terminate = True\n",
    "\n",
    "            \n",
    "        if self.ball_x <= 0:     # hitting left bound\n",
    "            self.ball_x = -self.ball_x\n",
    "            self.velocity_x = -self.velocity_x\n",
    "        if self.ball_y <= 0:     # hitting upper bound\n",
    "            self.ball_y = -self.ball_y\n",
    "            self.velocity_y = -self.velocity_y\n",
    "        if self.ball_y  >= 1:    # hitting right bound\n",
    "            self.ball_y = 2 - self.ball_y\n",
    "            self.velocity_y = -self.velocity_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(s):\n",
    "    b_x = math.floor(s.ball_x * 12)\n",
    "    b_y = math.floor(s.ball_y * 12)\n",
    "    if s.velocity_x > 0:\n",
    "        v_x = 1\n",
    "    else:\n",
    "        v_x = 0    # velocity_x <= 0 map to 0\n",
    "\n",
    "    v_y = 0\n",
    "    if s.velocity_y > 0 and abs(s.velocity_y) > 0.015:\n",
    "        v_y = 1\n",
    "    elif s.velocity_y < 0 and abs(s.velocity_y) > 0.015:    #velocity_y < 0.015 map to 2\n",
    "        v_y = 2\n",
    "\n",
    "    #print(\"paddle_y\", s.paddle_y)\n",
    "    p = math.floor(s.paddle_y / (1 - 0.2) * 12)\n",
    "    if p == 12:\n",
    "        p = 11\n",
    "    #print(\"p\", p)\n",
    "\n",
    "    return (b_x ,b_y, v_x, v_y, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(state):\n",
    "    next_ball_x = state.ball_x + state.velocity_x\n",
    "\n",
    "    if next_ball_x >= 1:        # hitting right bound\n",
    "        if state.ball_y >= state.paddle_y and state.ball_y <= state.paddle_y + 0.2:    # hitting paddle\n",
    "            return 1\n",
    "        else:     # missing paddle\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_up(current_state):\n",
    "    #print(\"up current\", match(current_state))\n",
    "    new_state = State(current_state.ball_x, current_state.ball_y, current_state.velocity_x, \\\n",
    "                      current_state.velocity_y, current_state.paddle_y)\n",
    "    new_state.up()\n",
    "    #print(\"new state\", match(new_state))\n",
    "    return new_state\n",
    "\n",
    "def get_down(current_state):\n",
    "    new_state = State(current_state.ball_x, current_state.ball_y, current_state.velocity_x, \\\n",
    "                      current_state.velocity_y, current_state.paddle_y)\n",
    "    new_state.down()\n",
    "    return new_state\n",
    "\n",
    "def get_no_move(current_state):\n",
    "    new_state = State(current_state.ball_x, current_state.ball_y, current_state.velocity_x, \\\n",
    "                      current_state.velocity_y, current_state.paddle_y)\n",
    "    new_state.update()\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_Q(current_state):\n",
    "    (b_x ,b_y, v_x, v_y, p) = match(get_up(current_state))\n",
    "    Q_up = Q_table[b_x][b_y][v_x][v_y][p][0]\n",
    "    \n",
    "    (b_x ,b_y, v_x, v_y, p) = match(get_down(current_state))\n",
    "    #print(b_x ,b_y, v_x, v_y, p)\n",
    "    Q_down = Q_table[b_x][b_y][v_x][v_y][p][1]\n",
    "    \n",
    "    (b_x ,b_y, v_x, v_y, p) = match(get_no_move(current_state))\n",
    "    Q_no_move = Q_table[b_x][b_y][v_x][v_y][p][2]\n",
    "    \n",
    "    #print(Q_up, Q_down, Q_no_move)\n",
    "    \n",
    "    return max(Q_up, Q_down, Q_no_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_f(current_state):\n",
    "    (b_x ,b_y, v_x, v_y, p) = match(get_up(current_state))\n",
    "    if N_sa[b_x][b_y][v_x][v_y][p][0] < N_e:\n",
    "        f_up = 0\n",
    "    else:\n",
    "        f_up = Q_table[b_x][b_y][v_x][v_y][p][0]\n",
    "    \n",
    "    (b_x ,b_y, v_x, v_y, p) = match(get_down(current_state))\n",
    "    if N_sa[b_x][b_y][v_x][v_y][p][1] < N_e:\n",
    "        f_down = 0\n",
    "    else:\n",
    "        f_down = Q_table[b_x][b_y][v_x][v_y][p][1]\n",
    "        \n",
    "    (b_x ,b_y, v_x, v_y, p) = match(get_no_move(current_state))\n",
    "    if N_sa[b_x][b_y][v_x][v_y][p][2] < N_e:\n",
    "        f_no_move = 0\n",
    "    else:\n",
    "        f_no_move = Q_table[b_x][b_y][v_x][v_y][p][2]\n",
    "    \n",
    "    if f_up == f_down and f_down == f_no_move:\n",
    "        return np.random.randint(3)\n",
    "    \n",
    "    return np.argmax([f_up, f_down, f_no_move])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(state):\n",
    "    (b_x ,b_y, v_x, v_y, p) = match(state)\n",
    "    num_visited = N_sa[b_x][b_y][v_x][v_y][p][a] \n",
    "    return 60 / (60 + num_visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_table = np.zeros((12, 12, 2, 3, 12, 3)) # x, y, v_x, v_y, paddle, action\n",
    "Q_additional_state = -1                   # x >= 1 state\n",
    "N_sa = np.zeros((12, 12, 2, 3, 12, 3))    # x, y, v_x, v_y, paddle, action\n",
    "\n",
    "s = State(0,0,0,0,0)\n",
    "s_empty = True\n",
    "a = 0\n",
    "r = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''action: 0-up, 1-down, 2-no_move'''\n",
    "def Q_agent(current_state, t):\n",
    "    global s_empty\n",
    "    global s\n",
    "    global a\n",
    "    global r\n",
    "    global N_sa\n",
    "    global Q\n",
    "    if current_state.terminate:\n",
    "        (b_x ,b_y, v_x, v_y, p) = match(s)\n",
    "        #Q_table[b_x][b_y][v_x][v_y][p][3] = reward(current_state)\n",
    "\n",
    "    if s_empty is False:\n",
    "        # increment N_s\n",
    "        (b_x ,b_y, v_x, v_y, p) = match(s)\n",
    "        #print(b_x ,b_y, v_x, v_y, p, a)\n",
    "        N_sa[b_x][b_y][v_x][v_y][p][a] += 1\n",
    "        #print(N_sa[b_x][b_y][v_x][v_y][p][a])\n",
    "        \n",
    "        Q_table[b_x][b_y][v_x][v_y][p][a] =  Q_table[b_x][b_y][v_x][v_y][p][a] + \\\n",
    "                            alpha(s)* (r + gamma * max_Q(current_state) - Q_table[b_x][b_y][v_x][v_y][p][a])\n",
    "        \n",
    "    else:\n",
    "        s_empty = False\n",
    "    \n",
    "    #s.empty = False\n",
    "    s = copy.deepcopy(current_state)\n",
    "    #print(\"s\", match(s))\n",
    "    \n",
    "    (b_x ,b_y, v_x, v_y, p) = match(current_state)\n",
    "    a = argmax_f(current_state)\n",
    "    \n",
    "    r = reward(current_state)\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_ = 1\n",
    "num_bounce = 0\n",
    "total_num_bounce = 0\n",
    "\n",
    "\n",
    "bounce_counter = []\n",
    "state_counter = []\n",
    "idx = []\n",
    "for i in range(10000):\n",
    "    idx.append(i)\n",
    "    s = State(0.5, 0.5, 0.03, 0.01, 0.4)\n",
    "    current_state = copy.deepcopy(s)\n",
    "    print(\"round: \", i)\n",
    "    num_bounce = 0\n",
    "    while s.terminate is False:\n",
    "        #s.print_state()\n",
    "        next_action = Q_agent(current_state, t_)\n",
    "        #print(\"current state before action\", match(current_state))\n",
    "        #print(\"next action\", next_action)\n",
    "        if next_action == 0:\n",
    "            current_state.up()\n",
    "        if next_action == 1:\n",
    "            current_state.down()\n",
    "        if next_action == 2:\n",
    "            current_state.update()\n",
    "        #print(\"current state\", match(current_state))\n",
    "    t_ += 1\n",
    "    bounce_counter.append(num_bounce)\n",
    "    print(\"bounce:\", num_bounce)\n",
    "    total_num_bounce += num_bounce\n",
    "    visited_states = np.count_nonzero(Q_table)\n",
    "    print(\"state visited: \",visited_states)\n",
    "    state_counter.append(visited_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average bouncing per game: \", total_num_bounce / 10000)\n",
    "\n",
    "print(\"totoal state visited after training: \", np.count_nonzero(Q_table))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = np.array(idx)\n",
    "bounce_counter = np.array(bounce_counter)\n",
    "state_counter = np.array(state_counter)\n",
    "\n",
    "plt.plot(idx, state_counter, 'r--', label = 'visited states')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(bounce_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(idx, bounce_counter, 'g', label = 'bounce_counter')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(bounce_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sorted(Q_table[np.nonzero(Q_table)],reverse=True), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sorted(N_sa[np.nonzero(N_sa)],reverse=True), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (N_sa[np.nonzero(N_sa)])\n",
    "\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = N_sa[np.nonzero(N_sa)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (stat.mean(data), stat.median(data), stat.mode(data))\n",
    "\n",
    "print (stat.median_low(data), stat.median_high(data))\n",
    "\n",
    "print (stat.median_grouped(data))\n",
    "\n",
    "print (stat.harmonic_mean(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stat.stdev(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_agent_test(current_state, t):\n",
    "    global s_empty\n",
    "    global s\n",
    "    global a\n",
    "    global r\n",
    "    global N_sa\n",
    "    global Q\n",
    "    if current_state.terminate:\n",
    "        (b_x ,b_y, v_x, v_y, p) = match(s)\n",
    "        #Q_table[b_x][b_y][v_x][v_y][p][3] = reward(current_state)\n",
    "\n",
    "    if s_empty is False:\n",
    "        # increment N_s\n",
    "        (b_x ,b_y, v_x, v_y, p) = match(s)\n",
    "        \n",
    "    else:\n",
    "        s_empty = False\n",
    "    \n",
    "    #s.empty = False\n",
    "    s = copy.deepcopy(current_state)\n",
    "    #print(\"s\", match(s))\n",
    "    \n",
    "    (b_x ,b_y, v_x, v_y, p) = match(current_state)\n",
    "    a = argmax_f_test(current_state)\n",
    "    \n",
    "    r = reward(current_state)\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_f_test(current_state):\n",
    "    (b_x ,b_y, v_x, v_y, p) = match(get_up(current_state))\n",
    "    f_up = Q_table[b_x][b_y][v_x][v_y][p][0]\n",
    "    \n",
    "    (b_x ,b_y, v_x, v_y, p) = match(get_down(current_state))\n",
    "    f_down = Q_table[b_x][b_y][v_x][v_y][p][1]\n",
    "        \n",
    "    (b_x ,b_y, v_x, v_y, p) = match(get_no_move(current_state))\n",
    "    f_no_move = Q_table[b_x][b_y][v_x][v_y][p][2]\n",
    "    \n",
    "    if f_up == f_down and f_down == f_no_move:\n",
    "        return np.random.randint(3)\n",
    "    \n",
    "    return np.argmax([f_up, f_down, f_no_move])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_ = 1\n",
    "num_bounce = 0\n",
    "total_num_bounce = 0\n",
    "\n",
    "state_counter = []\n",
    "bounce_counter = []\n",
    "\n",
    "for i in range(1000):\n",
    "    s = State(0.5, 0.5, 0.03, 0.01, 0.4)\n",
    "    current_state = copy.deepcopy(s)\n",
    "    print(\"round: \", i)\n",
    "    num_bounce = 0\n",
    "    while s.terminate is False:\n",
    "        #s.print_state()\n",
    "        next_action = Q_agent_test(current_state, t_)\n",
    "        #print(\"current state before action\", match(current_state))\n",
    "        #print(\"next action\", next_action)\n",
    "        if next_action == 0:\n",
    "            current_state.up()\n",
    "        if next_action == 1:\n",
    "            current_state.down()\n",
    "        if next_action == 2:\n",
    "            current_state.update()\n",
    "        #print(\"current state\", match(current_state))\n",
    "    t_ += 1\n",
    "    bounce_counter.append(num_bounce)\n",
    "    print(\"bounce:\", num_bounce)\n",
    "    total_num_bounce += num_bounce\n",
    "    num_state = np.count_nonzero(Q_table)\n",
    "    print(\"state visited: \",num_state)\n",
    "    state_counter.append(num_state)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average bouncing per game: \", total_num_bounce / 1000)\n",
    "\n",
    "print(\"totoal state visited after training: \", np.count_nonzero(Q_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
